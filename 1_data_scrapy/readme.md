# 以“南京大屠杀”作为关键字进行数据爬取及数据分析与数据可视化

## Part1. 数据爬取

### 1. 需要爬什么（爬取内容）

能爬到的信息

- 关于推文本身的信息（推文的发推时间，推文正文，推文的hashtag，推文的ID，推文的附带的多媒体文件信息，推文的点赞收藏Follow，推文的评论，等等）
- 关于发推用户的信息（发推用户的ID，姓名，性别，地理位置，Description，Follow和Followed的用户数，账户创建时间，用户类别，等等）

我所需要的信息

- 爬取中英日三语的关于关键词”南京大屠杀“的推文，提取其中的hashtag，可以绘制每一类语言的推文hashtag词云图，还可以绘制三种语言的社会关系网络图

通过能得到的信息，我还能做些什么

- 将爬取到的正文提取出来，通过分词的方法提取关键词，作为新的hashtag替代（原因：hashtag不能很好的概括推文的内容），以作为下一阶段的词云图和社会关系网络图的数据来源
- 对爬取到的full-text进行情感分析，结合上一步的操作，我们可以将情感赋值不同的颜色，将词云图和社会关系网络图完善为具有感情色彩的词云图和社会关系网络图
- 在对某个用户数据量足够大的情况下，我们可以针对这个用户的推文，判断猜测他的职业，兴趣爱好，家庭关系，社会阶层
- 基于发推时间，发推用户性别，发推用户年龄，发推人的社会阶层等，以及发推时的推文情感（这种适合针对个人的那种日常推文），进行频繁项集，扎到其中的频繁模式

### 2. 用什么方法爬（爬虫方法）

1. requests
   1. 作为一个requests的忠诚fans（已经很久不用urllib了），首先还是用requests派的方式解决问题啦
   2. requests的话，有以下几种方式
      1. 调用现成的已经写好的Twitter爬虫库（Github上面一搜一大把）
         1. 优点：emm，只能说用着都一样，没啥特别的
         2. 缺点: requests的共性，server那边断掉（不给数据了）以后客户端不好处理（通常爬虫会直接停止掉）
         3. 注意的地方：前期配置代理，或者用SSTap等没有代理端口的代理软件（可能只是我没找到端口在哪儿，但是跟SSR或者V2RAY还是有区别的）
      2. 用推特的开发者账号，自己造轮子，但是开发者账号我当时没有申请到，，，，所以这一条没有下文
      3. 自己抓包分析
         1. 推特的包还是比较好分析，浏览器里面过滤adaptive.json一般就能找到，这个json文件也就是我们需要的数据文件了
         2. 需要注意的是get方法的参数param和header，其中的具体参数请详见该网页 [Twitter推特高级搜索接口分析及爬虫编写](https://zhuanlan.zhihu.com/p/422958616)
         3. 这部分是有代码滴，代码详情请见 [面向Twitter的Requests爬虫](./main_requests_for_scrapy.py)
2. selenium
   1. 我从开始学selenium我就挺嫌弃它的，关键是因为它太慢了（就算改成无界面启动也很慢），然后这次的爬虫，只能说，selenium真香
   2. selenium在速度上依旧没有什么优势，但是它稳定呐，requests方式一接收到无数据的空包就会炸掉，而selenium动一动滚动条就可以轻松解决，只能说是很快乐了
   3. 有一个小问题，就是selenium只能切换网页并提取页面的html代码，但是没法把拿到的json数据存下来（也有可能是我没有找到方法）
      1. 曾经做过尝试，就是对浏览器的cache进行解包提取我要的信息，但是cache是大小是固定的，所以它会经常被清理，因此将数据没法用这个方法拿出来滴）
      2. 暂时的方法是使用抓包软件Fiddler来Capture流量，将浏览器get过程中拿到的adaptive.json存下来，具体对于Fiddler的用法请见 [Fiddler简介与安装使用](https://www.cnblogs.com/likeyan/p/15887711.html)
   4. 当然，这部分也是有代码滴，代码详情见 [面向Twitter的Selenium模拟浏览器抓包](./main_for_selenium_webdriver.py)
### 3. 拿到的数据用什么来存（数据存储方法）
   
1. json
2. 还是json（最好不要用数据库，因为很多数据都是只处理一次，而数据库注重于多次的增删改查，可能数据库只有在去重的时候才比较好用）
3. 最后用一个json整个起来就好了，整合的时候先将一个分类里面的重复元素去掉，不用分类之间的重复推文可以保留

### 4. 爬取的过程中应该注意哪些？（Attention）

1. 爬虫前的代理设置
   1. 在使用现成的轮子的时候，都要先进行代理配置，配置代理ip地址和代理端口
   2. selenium方法抓包的时候，需要注意Fiddler的代理设置和V2ray或SSR等的代理会不会冲突（Fiddler也是一种代理）
   3. 大概就先这样吧，以后想到什么了再补